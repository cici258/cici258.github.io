<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[scrapy 初探]]></title>
    <url>%2Fscrapy-%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[scrapy四部曲 新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目（1:scrapy startproject mySpider 2：scrapy genspider xxx “xxx.cn”） 明确目标 （编写items.py）：明确你想要抓取的目标，创建数据模型类。 items.pyitems.py里存放的是我们要爬取数据的字段信息,比如我们要爬去图片信息，文章标题，标签，价格，那么items.py就可以这么定义： 123456class JobItem(scrapy.Item): img = scrapy.Field() title = scrapy.Field() tag = scrapy.Field() price = scrapy.Field() ... 制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页 爬数据在当前目录下输入命令，将在mySpider/spider目录下创建一个名为xxx的爬虫，并指定爬取域的范围：scrapy genspider xxx “xxx.cn”打开 mySpider/spider目录里的 xxx.py，默认增加了下列代码: 1234567891011import scrapyclass ItcastSpider(scrapy.Spider): name = "xxx" allowed_domains = ["xxx.cn"] start_urls = ( 'http://www.xxx.cn/', ) def parse(self, response): pass parse(self, response) ：解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，主要作用如下： 负责解析返回的网页数据(response.body)，提取结构化数据(生成item)生成需要下一页的URL请求。将start_urls的值修改为需要爬取的第一个url。 取数据12345678910111213141516171819202122232425from mySpider.items import JobItem # 导入我们创建好的模型类def parse(self, response): items = [] for each in response.xpath("//div[@class='li_txt']"): # 将我们得到的数据封装到一个 `JobItem` 对象 item = JobItem() #extract()方法返回的都是unicode字符串 name = each.xpath("h3/text()").extract() title = each.xpath("h4/text()").extract() info = each.xpath("p/text()").extract() #xpath返回的是包含一个元素的列表 item['name'] = name[0] item['title'] = title[0] item['info'] = info[0] #items.append(item) #将获取的数据交给pipelines yield item # 返回数据，不经过pipeline #return items 存储内容 （pipelines.py）：设计管道存储爬取内容 scrapy的项目结构： items.py 负责数据模型的建立，类似于实体类。 middlewares.py 自己定义的中间件。 pipelines.py 负责对spider返回数据的处理。 settings.py 负责对整个爬虫的配置。 spiders目录 负责存放继承自scrapy的爬虫类。 scrapy.cfg scrapy基础配置 scrapy架构图Scrapy Engine(引擎): 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。 Scheduler(调度器): 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。 Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理， Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)， Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方. Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。 Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests） pipeline.pypipeline主要是对spiders中爬虫的返回的数据的处理，这里我们可以让写入到数据库，也可以让写入到文件等等。]]></content>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程爬取猫眼电影TOP100]]></title>
    <url>%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1TOP100%2F</url>
    <content type="text"><![CDATA[使用requests库爬取猫眼电影榜单top10012345678910111213141516171819202122232425262728293031323334353637383940414243import requestsimport jsonimport re from multiprocessing import Poolfrom requests.exceptions import RequestExceptiondef get_longpage(url): #获取单页数据 try: response = requests.get(url) if response.status_code == 200: return response.text return None except RequestException: return Nonedef parse_one_page(html): #解析获取到的数据 pattern = re.compile('&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?&lt;a.*?&gt;(.*?)' +'&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p&gt;.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;',re.S) #re.compile() 将正则表达式的字符串形式编译为Pattern实例 items = re.findall(pattern,html) for item in items: #把数据生成字典形式 yield &#123; 'index': item[0], 'image': item[1], 'title': item[2], 'actor': item[3].strip()[3:], 'time': item[4].strip()[5:], 'score': item[5]+item[6] &#125;def write_to_file(content): #写入文件 with open('result.txt','a',encoding='utf-8') as f: f.write(json.dumps(content,ensure_ascii=False) + '\n') f.close()def main(page): url = "https://maoyan.com/board/4?offset=" + str(page) html = get_longpage(url) for item in parse_one_page(html): write_to_file(item)if __name__ == '__main__': pool = Pool() #多线程 pool.map(main,[i*10 for i in range(10)])]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[正则表达式符号与方法常用符号图片看不太清楚，可以右键另存为~ 或者鼠标拖动一下到另外一个网页查看 - - 常用方法：findall()：匹配所有符合规律的内容 返回包含结果的列表。 传入参数re.S 使 . 包括 \n 。search()：匹配并提取第一个符合规律的内容，返回一个正则表达式对象（Object）。 sub()：替换符合规律的内容，返回替换后的值。sub()应用：1234567old_url = "http://www.baidu.com/?pageNum=1"for i in range(1,total_page+1): new_links = re.sub('pageNum=\d+','pageNum=%d' %i , old_url, re.S) print(new_links)#输出结果http://www.baidu.com/?pageNum=1http://www.baidu.com/?pageNum=2.....(一直到20)]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS居中]]></title>
    <url>%2FCSS%E5%B1%85%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[文字垂直居中height和line-height设置成一样的 块元素垂直居中于父元素将父元素设置为相对定位 position：relative，子元素设置为绝对定位 position：absolute；top：50%；margin-top设置为负height的一半 块元素容器水平居中第一种：margin：0 auto；第二种：width: 100px;left:50%;margin-left:-50px; (负边距居中) 背景图覆盖模式在父元素上添加background-size：cover。]]></content>
      <categories>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flex布局]]></title>
    <url>%2FFlex%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[Flex 布局在传统的方式中，我们通常会设置盒模型的 display、position、float 等属性来进行布局，对于一些特殊布局运用起来不是很方便，比如垂直居中水平居中，如果运用了浮动特性的话，就需要清除浮动，不但比较麻烦，一不小心还会出现意料之外的布局，最后呈现的结果往往不尽人意。 Flexbox（全称 Flexible Box）布局，也叫 Flex 布局，意为“弹性布局”，顾名思义，Flex 布局中的元素具有可伸缩性，通过设置父元素的 display 属性为 display: flex | inline-flex; 其子元素便有了伸缩性，即使在子元素的宽高不确定的情况下，也能通过设置相关 css 属性来决定子元素的对齐方式、所占比例和空间分布。 Flex布局基本架构 图中的囊括概念有几点： Flex 布局是一整个模块，其中父元素称为 flex container，意为容器；子元素称为 flex item，意为项目； Flex 布局中有两条看不见的轴线：主轴（main axis）和交叉轴（cross axis）。默认的主轴是平行的，交叉轴是垂直于主轴的； 主轴的开始位置叫 main start，结束位置叫 main end；交叉轴的开始位置叫 cross start，结束位置叫 cross end； 子元素在主轴方向上的大小称为 main size，在交叉轴方向上的大小称为 cross size。 在常规的布局中，浏览器是从左到右排列，挤不下了就换行，在这种情况下，主轴是水平方向，交叉轴是垂直方向，主轴是从左到右，交叉轴是从上到下。在 Flex 布局中，默认的主轴方向也是水平的，交叉轴是垂直的，通过改变 flex-direction 和 flex-wrap 的属性值可以分别改变两个轴的方向和它们的开始位置、起始位置，这就让布局更加灵活多变了。 Felx布局容器的六个属性 flex-direction：定义主轴的方向，即项目的排列方向。 属性值：row(横1234) row-reverse column(竖1234) column-reverse flex-wrap：用来定义当一行放不下时，项目如何换。属性值：nowwrap(不换行) wrap(换行，第一行在上面) wrap-reverse(换行) flex-flow：flex-direction 和 flex-wrap 的简写，默认值是 row no-wrap。 justify-content：定义项目在主轴上的对齐方式。属性值：flex-start flex-end center space-between space-around align-items：定义项目在交叉轴上如何对齐。 align-content：定义了多根轴线的对齐方式。若此时主轴在水平方向，交叉轴在垂直方向，align-content 就可以理解为多行在垂直方向的对齐方式。项目排列只有一行时，该属性不起作用。 项目属性 order: 定义了项目的排列顺序，默认值为 0，数值越小，排列越靠前。 flex-grow: 定义了项目的放大比例，默认为 0，也就是即使存在剩余空间，也不会放大。 flex-shrink: 定义了项目的缩小比例，默认为 1，即当空间不足时，项目会自动缩小。 flex-basis: 定义了在分配多余的空间之前，项目占据的主轴空间，默认值为 auto，即项目原来的大小。浏览器会根据这个属性来计算主轴是否有多余的空间。 flex: 属性是 flex-grow、flex-shrink、flex-basis 的缩写，默认值是 0 1 auto，后两个属性可选。 align-self：用来定义单个项目与其他项目不一样的对齐方式，可以覆盖 align-items 属性。默认属性值是 auto，即继承父元素的 align-items 属性值。当没有父元素时，它的表现等同于 stretch。 简单实例三栏布局12345&lt;div class="container"&gt; &lt;div class="center"&gt;center&lt;/div&gt; &lt;div class="left"&gt;left&lt;/div&gt; &lt;div class="right"&gt;right&lt;/div&gt;&lt;/div&gt; 123456789101112131415161718.container &#123; display: flex;&#125;.center &#123; height: 150px; background-color: #94E8FF;&#125;.left &#123; width: 100px; height: 150px; background-color: #FFB5BF;&#125;.right &#123; width: 200px; height: 150px; background-color: #8990D5;&#125; 如何将 .left 排列在最左边，和如何将 .center 占满剩余空间？order 属性可以改变项目的排列顺序，flex-grow 可以定义项目的放大比例。1234567.left &#123; order: -1;&#125;.center &#123; flex-grow: 1; /* flex: 1; 也行 */&#125; 居中问题当子元素的高度不确定时，处理垂直居中就比较麻烦，但是使用 Flex 布局中容器有关对齐方式的属性便能快速解决，以下代码子元素在父元素中是水平、垂直居中的。12345.container &#123; display: flex; justify-content: center; align-items: center;&#125; 推荐阅读：Flex 布局教程：实例篇。]]></content>
      <categories>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS 盒模型]]></title>
    <url>%2FCSS%E7%9B%92%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[在网页布局中，我们可以将 HTML 标签看成一个个矩形盒子，盒模型就是用来描述这些矩形盒子所占的空间大小。 相关属性在浏览器中打开“开发者工具”，用最左侧的箭头图标选中右侧的 div 元素，查看“Elements”下面的“Computed”，便可以一目了然的查看选择元素的各类属性。请看下图： padding 指内边距，是元素内容和边框之间的部分, margin 指外边距，用来定义元素周围的空间。 盒模型的分类由于浏览器的差异性，盒模型分为标准盒模型和IE盒模型，它们的呈现方式和对盒子大小的计算略有不同。 标准盒模型 元素的 width、height 只包含内容 content，不包含 border 和 padding 值； 盒子的大小由元素的宽高、边框和内边距决定。 IE盒模型 元素的 width、height 不仅包括 content，还包括 border 和 padding； 盒子的大小取决于 width、height，修改 border 和 padding 值不能改变盒子的大小。]]></content>
      <categories>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
</search>
